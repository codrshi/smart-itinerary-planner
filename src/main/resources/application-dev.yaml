spring:
  devtools:
    restart:
      enabled: true
  ai:
    openai:
      apiKey: notNeededForLocalLLM
      chat:
        options:
          model: ai/llama3.2
        base-url: http://localhost:12434

itinerary:
  redis:
    rate-limiting:
      tokens-per-period: 1
      period: 5000
  async:
    corePoolSize: 5
    maxPoolSize: 10
    queueCapacity: 50
    timeLimitScheduler:
      corePoolSize: 4

logging:
  level:
    com:
      codrshi:
        smart_itinerary_planner: DEBUG
    org:
      springframework:
        security: DEBUG
        web: DEBUG
        boot: DEBUG
        data: DEBUG
        ai: DEBUG
  pattern:
    console: "%cyan(%d{HH:mm:ss}) %highlight([%thread]) %highlight(%-5level) %green(%logger{36}) %magenta([%X{X-Trace-Id}]) - %msg%n"